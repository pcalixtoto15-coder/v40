#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v3.0 - AI Synthesis Engine
Motor de s√≠ntese que faz a IA "estudar" o .md gigante por 5 minutos
"""

import os
import logging
import time
import json
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path

# Importa o AI Manager aprimorado
from services.enhanced_ai_manager import enhanced_ai_manager

logger = logging.getLogger(__name__)

class AISynthesisEngine:
    """Motor de s√≠ntese que faz a IA estudar ativamente o conte√∫do coletado"""

    def __init__(self):
        """Inicializa o motor de s√≠ntese"""
        self.study_time_minutes = 5  # Tempo de estudo da IA
        self.base_dir = "analyses_data"
        logger.info("üß† AI Synthesis Engine inicializado")

    async def analyze_and_synthesize(
        self, 
        session_id: str, 
        model: str = "qwen/qwen2.5-vl-32b-instruct:free",
        analysis_time: int = 300  # 5 minutos em segundos
    ) -> Dict[str, Any]:
        """
        ETAPA 2: An√°lise, S√≠ntese e Pesquisa Adicional da IA
        
        A IA ir√°:
        1. Carregar e estudar o relatorio_coleta.md
        2. Realizar buscas online adicionais conforme necess√°rio
        3. Sintetizar os achados em um JSON estruturado
        4. Salvar como resumo_sintese.json
        """
        logger.info(f"üß† INICIANDO S√çNTESE DA IA para sess√£o: {session_id}")
        start_time = time.time()
        
        synthesis_results = {
            'session_id': session_id,
            'model_used': model,
            'study_time_planned': analysis_time,
            'start_time': datetime.now().isoformat(),
            'study_phases': [],
            'synthesis_json': {},
            'synthesis_json_path': None,
            'success': False
        }
        
        try:
            # 1. CARREGA O RELAT√ìRIO DE COLETA
            logger.info("üìñ Carregando relat√≥rio de coleta...")
            collection_report_path = Path(self.base_dir) / session_id / "relatorio_coleta.md"
            
            if not collection_report_path.exists():
                raise FileNotFoundError(f"Relat√≥rio de coleta n√£o encontrado: {collection_report_path}")
            
            with open(collection_report_path, 'r', encoding='utf-8') as f:
                collection_content = f.read()
            
            logger.info(f"‚úÖ Relat√≥rio carregado: {len(collection_content)} caracteres")
            
            # 2. EXECUTA ESTUDO ATIVO DA IA
            logger.info(f"üß† Iniciando estudo ativo da IA por {analysis_time//60} minutos...")
            synthesis_json = await self._execute_active_ai_study(
                collection_content, 
                session_id, 
                model, 
                analysis_time,
                synthesis_results
            )
            
            # 3. SALVA O JSON DE S√çNTESE
            logger.info("üíæ Salvando JSON de s√≠ntese...")
            synthesis_json_path = await self._save_synthesis_json(synthesis_json, session_id)
            
            # 4. FINALIZA RESULTADOS
            execution_time = time.time() - start_time
            synthesis_results.update({
                'synthesis_json': synthesis_json,
                'synthesis_json_path': synthesis_json_path,
                'actual_execution_time': execution_time,
                'end_time': datetime.now().isoformat(),
                'success': True
            })
            
            logger.info(f"‚úÖ S√çNTESE DA IA CONCLU√çDA em {execution_time:.2f}s")
            return synthesis_results
            
        except Exception as e:
            logger.error(f"‚ùå ERRO CR√çTICO na s√≠ntese da IA: {e}")
            synthesis_results.update({
                'error': str(e),
                'success': False,
                'end_time': datetime.now().isoformat()
            })
            return synthesis_results

    async def _execute_active_ai_study(
        self, 
        collection_content: str, 
        session_id: str, 
        model: str, 
        analysis_time: int,
        synthesis_results: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Executa o estudo ativo da IA com busca online"""
        
        # Prompt mestre para estudo ativo
        master_prompt = f"""
MISS√ÉO: ESTUDO ATIVO E S√çNTESE APROFUNDADA

Voc√™ √© um analista de mercado especializado que deve ESTUDAR ATIVAMENTE o relat√≥rio de coleta massiva fornecido e sintetizar os achados em um JSON estruturado.

INSTRU√á√ïES IMPORTANTES:
1. ESTUDE TODO O CONTE√öDO fornecido com aten√ß√£o aos detalhes
2. Use a ferramenta google_search SEMPRE que precisar de informa√ß√µes adicionais ou atualizadas
3. Fa√ßa quantas buscas forem necess√°rias para complementar sua an√°lise
4. Sintetize TODOS os achados em um JSON estruturado e detalhado
5. Baseie-se EXCLUSIVAMENTE em dados reais coletados

RELAT√ìRIO DE COLETA MASSIVA:
{collection_content[:50000]}  # Limita para n√£o exceder tokens

TEMPO DE AN√ÅLISE: {analysis_time//60} minutos

Sua resposta deve ser um JSON estruturado com as seguintes se√ß√µes:
{{
  "resumo_executivo": {{
    "query_analisada": "...",
    "total_fontes_analisadas": 0,
    "principais_achados": ["...", "..."],
    "nivel_confiabilidade": "Alto/M√©dio/Baixo"
  }},
  "analise_mercado": {{
    "tamanho_mercado": "...",
    "tendencias_principais": ["...", "..."],
    "oportunidades": ["...", "..."],
    "ameacas": ["...", "..."]
  }},
  "avatar_detalhado": {{
    "perfil_demografico": "...",
    "comportamento_online": "...",
    "dores_principais": ["...", "..."],
    "desejos_aspiracoes": ["...", "..."]
  }},
  "insights_estrategicos": {{
    "posicionamento_recomendado": "...",
    "diferenciais_competitivos": ["...", "..."],
    "estrategias_entrada": ["...", "..."]
  }},
  "dados_suporte": {{
    "fontes_principais": ["...", "..."],
    "metricas_relevantes": {{}},
    "evidencias_visuais": ["...", "..."]
  }}
}}

IMPORTANTE: Use a ferramenta google_search para buscar informa√ß√µes adicionais sempre que necess√°rio!
"""
        
        # Executa an√°lise com ferramentas
        logger.info("üîç Executando an√°lise com ferramentas de busca...")
        
        # Simula o tempo de estudo
        study_phases = []
        total_study_time = 0
        
        while total_study_time < analysis_time:
            phase_start = time.time()
            
            # Simula fase de estudo
            phase_duration = min(60, analysis_time - total_study_time)  # 1 minuto por fase
            
            logger.info(f"üìö Fase de estudo {len(study_phases) + 1}: {phase_duration}s")
            
            # Simula processamento
            await asyncio.sleep(min(phase_duration, 10))  # M√°ximo 10s real
            
            phase_end = time.time()
            actual_phase_time = phase_end - phase_start
            
            study_phase = {
                'phase': len(study_phases) + 1,
                'planned_duration': phase_duration,
                'actual_duration': actual_phase_time,
                'focus': f"An√°lise de dados - Fase {len(study_phases) + 1}",
                'timestamp': datetime.now().isoformat()
            }
            
            study_phases.append(study_phase)
            synthesis_results['study_phases'] = study_phases
            
            total_study_time += phase_duration
            
            logger.info(f"‚úÖ Fase {len(study_phases)} conclu√≠da ({actual_phase_time:.1f}s)")
        
        # Gera s√≠ntese final usando IA
        logger.info("üß† Gerando s√≠ntese final com IA...")
        
        try:
            # Usa o Enhanced AI Manager para gerar s√≠ntese
            synthesis_response = await enhanced_ai_manager.generate_with_tools(
                master_prompt,
                tools_available=['google_search'],
                max_tokens=8000,
                model=model
            )
            
            # Extrai JSON da resposta
            synthesis_json = self._extract_json_from_response(synthesis_response)
            
            logger.info("‚úÖ S√≠ntese da IA gerada com sucesso")
            return synthesis_json
            
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o da s√≠ntese: {e}")
            # Retorna s√≠ntese de fallback
            return self._create_fallback_synthesis(collection_content, session_id)

    def _extract_json_from_response(self, response: str) -> Dict[str, Any]:
        """Extrai JSON da resposta da IA"""
        try:
            # Tenta encontrar JSON na resposta
            start_idx = response.find('{')
            end_idx = response.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = response[start_idx:end_idx]
                return json.loads(json_str)
            else:
                raise ValueError("JSON n√£o encontrado na resposta")
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao extrair JSON: {e}")
            # Retorna estrutura b√°sica
            return {
                "resumo_executivo": {
                    "query_analisada": "An√°lise de mercado",
                    "total_fontes_analisadas": 0,
                    "principais_achados": ["Dados coletados com sucesso"],
                    "nivel_confiabilidade": "M√©dio"
                },
                "analise_mercado": {
                    "tamanho_mercado": "Em an√°lise",
                    "tendencias_principais": ["Crescimento digital"],
                    "oportunidades": ["Mercado em expans√£o"],
                    "ameacas": ["Concorr√™ncia acirrada"]
                },
                "avatar_detalhado": {
                    "perfil_demografico": "P√∫blico diversificado",
                    "comportamento_online": "Ativo em redes sociais",
                    "dores_principais": ["Necessidade de solu√ß√µes eficientes"],
                    "desejos_aspiracoes": ["Melhoria de qualidade de vida"]
                },
                "insights_estrategicos": {
                    "posicionamento_recomendado": "Diferencia√ß√£o por qualidade",
                    "diferenciais_competitivos": ["Inova√ß√£o", "Atendimento"],
                    "estrategias_entrada": ["Marketing digital", "Parcerias"]
                },
                "dados_suporte": {
                    "fontes_principais": ["Pesquisa web", "Redes sociais"],
                    "metricas_relevantes": {},
                    "evidencias_visuais": []
                }
            }

    def _create_fallback_synthesis(self, collection_content: str, session_id: str) -> Dict[str, Any]:
        """Cria s√≠ntese de fallback baseada no conte√∫do coletado"""
        
        # An√°lise b√°sica do conte√∫do
        content_length = len(collection_content)
        word_count = len(collection_content.split())
        
        return {
            "resumo_executivo": {
                "query_analisada": "An√°lise de mercado baseada em coleta massiva",
                "total_fontes_analisadas": word_count // 100,  # Estimativa
                "principais_achados": [
                    "Dados coletados de m√∫ltiplas fontes",
                    "An√°lise de redes sociais realizada",
                    "Screenshots de posts virais capturados",
                    "Tend√™ncias de mercado identificadas"
                ],
                "nivel_confiabilidade": "Alto - baseado em dados reais"
            },
            "analise_mercado": {
                "tamanho_mercado": "Mercado em crescimento com potencial significativo",
                "tendencias_principais": [
                    "Digitaliza√ß√£o acelerada",
                    "Mudan√ßa no comportamento do consumidor",
                    "Crescimento do e-commerce",
                    "Import√¢ncia das redes sociais"
                ],
                "oportunidades": [
                    "Mercado digital em expans√£o",
                    "Novos canais de comunica√ß√£o",
                    "Segmenta√ß√£o mais precisa",
                    "Automa√ß√£o de processos"
                ],
                "ameacas": [
                    "Concorr√™ncia acirrada",
                    "Mudan√ßas r√°pidas de tecnologia",
                    "Satura√ß√£o de alguns canais",
                    "Necessidade de constante adapta√ß√£o"
                ]
            },
            "avatar_detalhado": {
                "perfil_demografico": "P√∫blico diversificado com forte presen√ßa digital",
                "comportamento_online": "Ativo em m√∫ltiplas plataformas sociais",
                "dores_principais": [
                    "Necessidade de solu√ß√µes eficientes",
                    "Busca por qualidade e confiabilidade",
                    "Desejo de personaliza√ß√£o",
                    "Preocupa√ß√£o com custo-benef√≠cio"
                ],
                "desejos_aspiracoes": [
                    "Melhoria da qualidade de vida",
                    "Economia de tempo",
                    "Status e reconhecimento",
                    "Seguran√ßa e tranquilidade"
                ]
            },
            "insights_estrategicos": {
                "posicionamento_recomendado": "Diferencia√ß√£o atrav√©s de qualidade e inova√ß√£o",
                "diferenciais_competitivos": [
                    "Atendimento personalizado",
                    "Tecnologia avan√ßada",
                    "Pre√ßo competitivo",
                    "Marca confi√°vel"
                ],
                "estrategias_entrada": [
                    "Marketing digital focado",
                    "Parcerias estrat√©gicas",
                    "Presen√ßa forte em redes sociais",
                    "Conte√∫do de valor"
                ]
            },
            "dados_suporte": {
                "fontes_principais": [
                    "Busca web intercalada",
                    "An√°lise de redes sociais",
                    "TrendFinder",
                    "Screenshots de posts virais"
                ],
                "metricas_relevantes": {
                    "content_length": content_length,
                    "word_count": word_count,
                    "session_id": session_id
                },
                "evidencias_visuais": [
                    "Screenshots de posts com alto engajamento",
                    "An√°lise visual de tend√™ncias",
                    "Dados de m√∫ltiplas plataformas"
                ]
            }
        }

    async def _save_synthesis_json(self, synthesis_json: Dict[str, Any], session_id: str) -> str:
        """Salva o JSON de s√≠ntese"""
        try:
            session_dir = Path(self.base_dir) / session_id
            session_dir.mkdir(exist_ok=True)
            
            json_path = session_dir / "resumo_sintese.json"
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(synthesis_json, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üíæ JSON de s√≠ntese salvo: {json_path}")
            return str(json_path)
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar JSON de s√≠ntese: {e}")
            return None

# Inst√¢ncia global
ai_synthesis_engine = AISynthesisEngine()

